{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Label classification\n",
    "\n",
    "#### Topic Modelling on the Reuters Dataset. \n",
    "\n",
    "Binary classification is where an input can be classified in to 2 categories\n",
    "\n",
    "Multi-class classification is where an input can be classified to any ONE of many categories\n",
    "\n",
    "Multi-label classification is where an input can be classified to ANY NUMBER of many categories \n",
    "\n",
    "In this notebook we'll explore multi-label classification within the field of topic modelling. In our case, stating the topics associated with a reuters news article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs\n",
    "- nltk is the natural language toolkit, where the reuters dataset is stored\n",
    "- the nltk corpus contains information about the reuters dataset\n",
    "- torch (pytorch) libraries contain helpful tools for deep learning including the dataloader and optimiser.\n",
    "You can learn more about the dataloader here \n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "- the model and tokeniser are loaded from the transformers library. \n",
    "- label_ranking_average_precision_score is an evaluation tool\n",
    "-  the counter class is helpful for complex counting over iterables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import torch.utils.data\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification , AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from the natural language toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/Ben/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 90 categories with which the documents can be labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_documents = reuters.fileids()\n",
    "reuters_categories = reuters.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Functions\n",
    "\n",
    "Before we get into the model, first we have defined a few functions which help us understand the reuters dataset.\n",
    "\n",
    "This function returns information about the reuters dataset, including the test:train split and the number of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_info(documents):\n",
    "\n",
    "    \"\"\"Information about Reuters dataset, such as number of training and test documents, and categories\"\"\"\n",
    "    train_docs = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "    test_docs = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "    print(str(len(documents)) + \" documents\")\n",
    "    print(str(len(train_docs)) + \" total train documents\")\n",
    "    print(str(len(test_docs)) + \" total test documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10788 documents\n",
      "7769 total train documents\n",
      "3019 total test documents\n"
     ]
    }
   ],
   "source": [
    "dataset_info(reuters_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the number of documents which are labeleld by each of the 90 categories. As this dataset is multi-label the sum of these figures will be more than the number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_per_category(categories):\n",
    "    \"\"\"Return the number of documents per category\"\"\"\n",
    "    def get_category_length_tuple(cat):\n",
    "        return (len(reuters.fileids(cat)), cat)\n",
    "    return [get_category_length_tuple(cat) for cat in categories]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2369, 'acq'),\n",
       " (58, 'alum'),\n",
       " (51, 'barley'),\n",
       " (105, 'bop'),\n",
       " (68, 'carcass'),\n",
       " (2, 'castor-oil'),\n",
       " (73, 'cocoa'),\n",
       " (6, 'coconut'),\n",
       " (7, 'coconut-oil'),\n",
       " (139, 'coffee'),\n",
       " (65, 'copper'),\n",
       " (3, 'copra-cake'),\n",
       " (237, 'corn'),\n",
       " (59, 'cotton'),\n",
       " (3, 'cotton-oil'),\n",
       " (97, 'cpi'),\n",
       " (4, 'cpu'),\n",
       " (578, 'crude'),\n",
       " (3, 'dfl'),\n",
       " (175, 'dlr'),\n",
       " (14, 'dmk'),\n",
       " (3964, 'earn'),\n",
       " (23, 'fuel'),\n",
       " (54, 'gas'),\n",
       " (136, 'gnp'),\n",
       " (124, 'gold'),\n",
       " (582, 'grain'),\n",
       " (9, 'groundnut'),\n",
       " (2, 'groundnut-oil'),\n",
       " (19, 'heat'),\n",
       " (22, 'hog'),\n",
       " (20, 'housing'),\n",
       " (16, 'income'),\n",
       " (6, 'instal-debt'),\n",
       " (478, 'interest'),\n",
       " (53, 'ipi'),\n",
       " (54, 'iron-steel'),\n",
       " (5, 'jet'),\n",
       " (67, 'jobs'),\n",
       " (8, 'l-cattle'),\n",
       " (29, 'lead'),\n",
       " (15, 'lei'),\n",
       " (2, 'lin-oil'),\n",
       " (99, 'livestock'),\n",
       " (16, 'lumber'),\n",
       " (49, 'meal-feed'),\n",
       " (717, 'money-fx'),\n",
       " (174, 'money-supply'),\n",
       " (6, 'naphtha'),\n",
       " (105, 'nat-gas'),\n",
       " (9, 'nickel'),\n",
       " (3, 'nkr'),\n",
       " (4, 'nzdlr'),\n",
       " (14, 'oat'),\n",
       " (171, 'oilseed'),\n",
       " (27, 'orange'),\n",
       " (3, 'palladium'),\n",
       " (40, 'palm-oil'),\n",
       " (3, 'palmkernel'),\n",
       " (32, 'pet-chem'),\n",
       " (12, 'platinum'),\n",
       " (6, 'potato'),\n",
       " (6, 'propane'),\n",
       " (3, 'rand'),\n",
       " (8, 'rape-oil'),\n",
       " (27, 'rapeseed'),\n",
       " (73, 'reserves'),\n",
       " (25, 'retail'),\n",
       " (59, 'rice'),\n",
       " (49, 'rubber'),\n",
       " (2, 'rye'),\n",
       " (286, 'ship'),\n",
       " (29, 'silver'),\n",
       " (34, 'sorghum'),\n",
       " (26, 'soy-meal'),\n",
       " (25, 'soy-oil'),\n",
       " (111, 'soybean'),\n",
       " (27, 'strategic-metal'),\n",
       " (162, 'sugar'),\n",
       " (2, 'sun-meal'),\n",
       " (7, 'sun-oil'),\n",
       " (16, 'sunseed'),\n",
       " (13, 'tea'),\n",
       " (30, 'tin'),\n",
       " (485, 'trade'),\n",
       " (124, 'veg-oil'),\n",
       " (283, 'wheat'),\n",
       " (29, 'wpi'),\n",
       " (59, 'yen'),\n",
       " (34, 'zinc')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_per_category(reuters_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories_per_documents(documents):\n",
    "    \"\"\"Reuters contains multilabeled documents.\n",
    "    This method returns the number of labels and the corresponding number of documents\n",
    "    e.g. 2:1173 means that there are 1173 documents with 2 categories (multilabel)\n",
    "    \"\"\"\n",
    "    def categories_per_document(fid):\n",
    "        return (len(reuters.categories(fid)), fid)\n",
    "\n",
    "\n",
    "    list_of_categories_per_doc = [\n",
    "    categories_per_document(doc) for doc in documents]\n",
    "    # Returns the number of documents that fall in multiple categories\n",
    "    return(Counter([a for (a, b) in list_of_categories_per_doc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By isolating the inner function of categories per document, we can look for a document where the number of labels is 15, and then return those labels. \n",
    "\n",
    "15 is the most labels that one document has in this dataset. \n",
    "Most documents have only 1 label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['coffee',\n",
       "   'copra-cake',\n",
       "   'corn',\n",
       "   'cotton',\n",
       "   'grain',\n",
       "   'palm-oil',\n",
       "   'palmkernel',\n",
       "   'rice',\n",
       "   'rubber',\n",
       "   'soy-meal',\n",
       "   'soybean',\n",
       "   'sugar',\n",
       "   'tea',\n",
       "   'veg-oil',\n",
       "   'wheat'],\n",
       "  'training/235')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categories_per_document(fid):\n",
    "        return (len(reuters.categories(fid)), fid)\n",
    "\n",
    "[(reuters.categories(doc),doc) for doc in reuters_documents if categories_per_document(doc)[0] == 15]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells set up  the test and train dataset and initialise the tokeniser and model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/Ben/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to /Users/Ben/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769 3019\n",
      "('AMERICAN STORES &lt;ASC> SEES LOWER YEAR NET\\n  American Stores Co said it\\n  expects to report earnings per share of 3.70 to 3.85 dlrs per\\n  share on sales of slightly over 14 billion dlrs for the year\\n  ended January 31.\\n      The supermarket chain earned 4.11 dlrs per share on sales\\n  of 13.89 billion dlrs last year.\\n      The company did not elaborate.\\n  \\n\\n', [21])\n"
     ]
    }
   ],
   "source": [
    "class Reuters(torch.utils.data.Dataset):\n",
    "    def __init__(self,mode = 'train', tokenise=False):\n",
    "        nltk.download(\"reuters\")\n",
    "        self.fileids = list(filter(lambda doc: doc.startswith(mode), reuters.fileids()))\n",
    "        self.text = [reuters.raw(fid) for fid in self.fileids]\n",
    "        self.category_to_index = {cat:index for (index,cat) in enumerate(reuters.categories())} \n",
    "        self.label = [[self.category_to_index[cat] for cat in reuters.categories(fid)] for fid in self.fileids]\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fileids)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return (self.text[index], self.label[index])\n",
    "   \n",
    "train_dataset = Reuters(\"train\")\n",
    "test_dataset = Reuters(\"test\")\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants are defined to specify the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "NUMBER_OF_CLASSES = 90\n",
    "BATCH_SIZE = 5\n",
    "NUMBER_OF_EPOCHS = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokeniser and model are initialised using the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokeniser = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUMBER_OF_CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the IMDB dataset, the documents are tokenised into parts of words. \n",
    "However the labels can no longer just be an adjacent list. Instead they are now a list of 90 dimensional tensors with each dimension indicating if the responding category describes the adjacent document. \n",
    "\n",
    "The commented out line allows us to test the evaluation method runs without running over the whole large dataset by reducing it to a single value. \n",
    "\n",
    "*** Need explanation of one-hot here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_test = tokeniser(test_dataset.text,truncation=True,padding=True) # these are all default args because of the tokeniser we've loaded with the model we've loaded. \n",
    "tokenised_train = tokeniser(train_dataset.text,truncation=True,padding=True)\n",
    "\n",
    "tokenised_test_dataset = [{\"labels\":nn.functional.one_hot(torch.tensor(label),num_classes=NUMBER_OF_CLASSES).sum(dim=0), \"input_ids\": text,\"attention_mask\":mask} for label,text,mask in zip(test_dataset.label,tokenised_test[\"input_ids\"],tokenised_test[\"attention_mask\"])]\n",
    "tokenised_train_dataset = [{\"labels\":nn.functional.one_hot(torch.tensor(label),num_classes=NUMBER_OF_CLASSES).sum(dim=0), \"input_ids\": text,\"attention_mask\":mask} for label,text,mask in zip(train_dataset.label,tokenised_train[\"input_ids\"],tokenised_train[\"attention_mask\"])]\n",
    "\n",
    "# tokenised_train_dataset = tokenised_train_dataset[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloader is created using the tokenised training dataset and the batch size. This structure will be used to feed the training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(tokenised_train_dataset, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this classification problem is multi-label, a challenge arises when adjusting the weights during training. \n",
    "Essentially the model can't just be rewarded when it get's a positive label right, it must also be rewarded when it get's a negative label right too. Otherwise it would just classify every label as correct every time. \n",
    "However, most of the time a particular category will not describe the document, meaning that rewarding the negative classification the same as the positive classification leads to the model always predicting that the documents are described by 0 categories. \n",
    "\n",
    "This is a problem of data sparcity which occurs in high dimensional spaces, or highly bias data. \n",
    "\n",
    "One solution is to weight the categories by how frequently they occus in the dataset. \n",
    "\n",
    "The function create_position_weights takes the train dataset, sums the labels and devides the number of positive cases per label by the total negative samples. \n",
    "\n",
    "When these weights are used when calculating the loss the model performs slightly better, although more can be done to reduce the affect of sparcity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_position_weights(tokenised_train_dataset):\n",
    "    labels = torch.stack([x[\"labels\"]   for x in tokenised_train_dataset ])\n",
    "    total_positive_samples = labels.sum().item()\n",
    "    total_negative_samples = torch.numel(labels)-total_positive_samples\n",
    "\n",
    "    # print(total_positive_samples,total_negative_samples)\n",
    "    positive_per_label = labels.sum(dim=0)\n",
    "    position_weights = total_negative_samples/positive_per_label\n",
    "    return position_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights are applied to the loss function used in the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = model.parameters()\n",
    "optimiser = optim.AdamW(params_to_update)\n",
    "position_weights = create_position_weights(tokenised_train_dataset)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=position_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training loop also calculates the running loss and running accuracy for each epoch. \n",
    "\n",
    "With these figures you can hopefully see the algorithm working in reducing the loss and increasing the accuracy. \n",
    "\n",
    "Each epoch the loop passes over the whole dataset in batches.\n",
    "\n",
    "As always, the model predicts an output and the loss is calculated by comparing this output with the labels associated with the input. \n",
    "\n",
    "Back propagation updates the paramaters of the model and the optimiser applies exponential smoothness.\n",
    "\n",
    "At the same time the predictions are fed into the epoch loss and epoch accuracy calculations which are printed each loop. \n",
    "\n",
    "Unfortunatley without a GPU this loop still takes a long time to run. So a pretrained model can be loaded from a file instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb#ch0000022?line=10'>11</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids,attention_mask\u001b[39m=\u001b[39m attention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb#ch0000022?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs[\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m], labels\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb#ch0000022?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb#ch0000022?line=13'>14</a>\u001b[0m optimiser\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Ben/INSTANT/NICD_SkillTransfer/TopicModelling/reuters_topic_modelling.ipynb#ch0000022?line=15'>16</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m input_ids\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/INSTANT/.venv/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/INSTANT/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# long running time\n",
    "running_loss = 0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in tqdm(range(NUMBER_OF_EPOCHS)):\n",
    "    for batch in train_dataloader: \n",
    "        optimiser.zero_grad()\n",
    "        input_ids = torch.stack(batch[\"input_ids\"], 1)\n",
    "        attention_mask = torch.stack(batch[\"attention_mask\"],1)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        outputs = model(input_ids,attention_mask= attention_mask)\n",
    "        loss = loss_fn(outputs[\"logits\"], labels.float())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item() * input_ids.size(0)\n",
    "        preds = (torch.sigmoid(outputs[\"logits\"])>0.5).int()\n",
    "        running_correct += torch.sum(preds==labels)\n",
    "    epoch_loss = running_loss/len(train_dataloader.dataset)\n",
    "    epoch_accuracy = running_correct.double()/(len(train_dataloader.dataset)*NUMBER_OF_CLASSES) \n",
    "    print(\"Epoch loss: \", epoch_loss)\n",
    "    print(\"Epoch Accuracy: \", epoch_accuracy.item())\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = f\"models/reuters_{MODEL_NAME}.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH,map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 2\n",
    "test_sample = tokenised_test_dataset[test_idx]\n",
    "test_input = torch.tensor(test_sample[\"input_ids\"],device = DEVICE).unsqueeze(0)\n",
    "test_mask = torch.tensor(test_sample[\"attention_mask\"],device = DEVICE).unsqueeze(0)\n",
    "test_label = test_sample[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK] japan to revise long - term energy demand downwards the ministry of international trade and industry ( miti ) will revise its long - term energy supply / demand outlook by august to meet a forecast downtrend in japanese energy demand, ministry officials said. miti is expected to lower the projection for primary energy supplies in the year [SEP]'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input\n",
    "\n",
    "tokeniser.convert_tokens_to_string(tokeniser.convert_ids_to_tokens([103,  2900,  2000,  7065,  5562,  2146,  1011,  2744,  2943,  5157,\n",
    "         28457,  1996,  3757,  1997,  2248,  3119,  1998,  3068,  1006, 10210,\n",
    "          2072,  1007,  2097,  7065,  5562,  2049,  2146,  1011,  2744,  2943,\n",
    "          4425,  1013,  5157, 17680,  2011,  2257,  2000,  3113,  1037, 19939,\n",
    "          2091,  7913,  4859,  1999,  2887,  2943,  5157,  1010,  3757,  4584,\n",
    "          2056,  1012, 10210,  2072,  2003,  3517,  2000,  2896,  1996, 13996,\n",
    "          2005,  3078,  2943,  6067,  1999,  1996,  2095,102]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\\n  The Ministry of International Trade and\\n  Industry (MITI) will revise its long-term energy supply/demand\\n  outlook by August to meet a forecast downtrend in Japanese\\n  energy demand, ministry officials said.\\n      MITI is expected to lower the projection for primary energy\\n  supplies in the year 2000 to 550 mln kilolitres (kl) from 600\\n  mln, they said.\\n      The decision follows the emergence of structural changes in\\n  Japanese industry following the rise in the value of the yen\\n  and a decline in domestic electric power demand.\\n      MITI is planning to work out a revised energy supply/demand\\n  outlook through deliberations of committee meetings of the\\n  Agency of Natural Resources and Energy, the officials said.\\n      They said MITI will also review the breakdown of energy\\n  supply sources, including oil, nuclear, coal and natural gas.\\n      Nuclear energy provided the bulk of Japan's electric power\\n  in the fiscal year ended March 31, supplying an estimated 27\\n  pct on a kilowatt/hour basis, followed by oil (23 pct) and\\n  liquefied natural gas (21 pct), they noted.\\n  \\n\\n\",\n",
       " [17, 49])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_sample\n",
    "# test_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_idx = 2350\n",
    "test_train_sample = tokenised_train_dataset[test_train_idx]\n",
    "test_train_input = torch.tensor(test_train_sample[\"input_ids\"],device = DEVICE).unsqueeze(0)\n",
    "test_train_mask = torch.tensor(test_train_sample[\"attention_mask\"],device = DEVICE).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BUFFTON CORP &lt;BUFF> BUYS B AND D INSTRUMENTS\\n  Buffton Corp said it completed\\n  the purchase of B and D Industruments Inc for two mln dlrs cash\\n  and 400,000 shares of common stock.\\n      It said B and D is a private company headquartered in\\n  Kansas, and had sales of 4,700,000 dlrs in 1986.\\n      Buffton said the company designs and manufactures aviation\\n  computer display systems and engine instrumentation.\\n  \\n\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.text[2350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(test_input,attention_mask= test_mask)[\"logits\"]\n",
    "# loss_fn(outputs, labels.float())\n",
    "\n",
    "print(\"score\",label_ranking_average_precision_score(test_label.unsqueeze(0), outputs.detach()))\n",
    "\n",
    "preds = (torch.sigmoid(outputs)>0.5).int()\n",
    "# preds = torch.sigmoid(outputs)\n",
    "print(preds,test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_mask\n",
    "test_sample\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = 10\n",
    "test_samples = tokenised_test_dataset[:test_idx]\n",
    "test_inputs = torch.stack([torch.tensor(test_sample[\"input_ids\"],device = DEVICE) for test_sample in test_samples])\n",
    "test_masks = torch.stack([torch.tensor(test_sample[\"attention_mask\"],device = DEVICE) for test_sample in test_samples])\n",
    "test_labels = torch.stack([test_sample[\"labels\"] for test_sample in test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 13675,  2050,  2853, 16319,  2751,  2005,  6146, 19875,  2078,\n",
       "         21469,  2869,  1011,  1059, 14341,  3636,  1004,  8318,  1025,  1059,\n",
       "         14341,  3636, 10495, 17953,  1028,  2056,  1996, 12360,  2009,  2003,\n",
       "          2877,  2097,  3477,  6146,  1012,  4583, 19875,  2078, 21469,  2869,\n",
       "          2005,  1996,  7654,  1997, 13675,  2050,  5183,  1005,  1055,  1004,\n",
       "          8318,  1025, 13675, 11057,  1012,  1055,  1028,  1004,  8318,  1025,\n",
       "         16319,  2751, 13866,  2100,  5183,  1028,  3131,  1010,  2988,  7483,\n",
       "          1012, 13675,  2050,  1998,  1059, 14341,  3636,  2106,  2025, 26056,\n",
       "          1996,  3976,  7483,  1012,  1059, 14341,  3636,  2097,  2907,  4008,\n",
       "          7473,  2102,  1997,  1996, 12360,  1010,  2096,  1004,  8318,  1025,\n",
       "         17151,  2102,  2860, 14341,  4219, 17953,  1028,  2097,  2907,  2676,\n",
       "          7473,  2102,  1998,  1004,  8318,  1025, 13675, 22504,  2271,  5471,\n",
       "         17953,  1028,  2756,  7473,  2102,  1010,  2009,  2056,  1999,  1037,\n",
       "          4861,  1012,  2004,  2988,  1010, 16319,  2751,  8617,  2048,  7134,\n",
       "          1999,  2530,  2660,  5155,  1037,  4117,  4261,  1010,  2199, 19471,\n",
       "          2015,  1997,  2751,  1037,  2095,  1012,  2009,  2036,  8617,  2019,\n",
       "         29341,  2751,  2622,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.16754075701311438\n"
     ]
    }
   ],
   "source": [
    "outputs = model(test_inputs,attention_mask= test_masks)[\"logits\"]\n",
    "# loss_fn(outputs, labels.float())\n",
    "\n",
    "print(\"score\",label_ranking_average_precision_score(test_labels, outputs.detach()))\n",
    "\n",
    "# preds = (torch.sigmoid(outputs)>0.5).int()\n",
    "# # preds = torch.sigmoid(outputs)\n",
    "# print(preds,test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e147a4062cc14d8132ddbab6c810acf2b57507c0a7010e464731e08cfaff5b7c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
